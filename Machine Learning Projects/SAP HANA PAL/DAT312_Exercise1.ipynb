{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT312 - Developing and deploying a SAP HANA ML scenario\n",
    "\n",
    "### Introduction - Telco Customer Churn\n",
    "- This scenario is based on telco customer data and focuses on predicting which customers are likely to churn, i.e. likely to cancel their contract next month.\n",
    "- Given is a data set CUSTOMERCHURN, which provides insight about each telco customer based on standard customer attributes and measures on current, previous month (_PM) and previous-previous month (_PPM) statistics. \n",
    "- This data set comprises historic information, hence the churn behavior is known (ContractActivityLabel) from the past, and is thus used for training a classification model. \n",
    "- A second data set NEWCUSTOMERCHURN comprises data from a new or the current month, describing the current customer state, where the churn status is not known and shall be predicted in order to take actions targeting customers which are likely to churn (cancel their contract and leave).\n",
    "\n",
    "\n",
    "### Exercise 1 - Build a ML scenario using the Python API for HANA ML\n",
    "- Build a simple machine learning model in SAP HANA using the python language to predict which customers are likely to churn.\n",
    "- SAP HANA provides a large set of machine learning libraries to deal with regression, classifications, forecasting etc. problems  \n",
    " - The libray we are going to use is the SAP HANA Predictive Analysis Library (PAL)\n",
    " - The algorithms in PAL can be accessed through the python language, the documentation of the HANA Python API for PAL can be found here https://help.sap.com/doc/0172e3957b5946da85d3fde85ee8f33d/2.0.03/en-US/html/hana_ml.html# \n",
    " - Here we are using jupyter-notebook as the user interface for the Python scripts and visualizations\n",
    " \n",
    "- Execute (run) the code blocks in this Notebook step by step\n",
    "- In Exercise 2 and following, the artefacts and SQL code generated here from Python will be build into SAP HANA design-time content and templates constructing a \"HANA ML scenario application\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Load the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import HANA database client library for Python\n",
    "from hdbcli import dbapi\n",
    "from hdbcli import dbapi\n",
    "print(dbapi.__name__)\n",
    "\n",
    "#Import HANA Dataframe and Algorithm classes from Python API package\n",
    "from hana_ml import dataframe\n",
    "from hana_ml.dataframe import ConnectionContext\n",
    "\n",
    "from hana_ml import algorithms\n",
    "from hana_ml.algorithms.pal import trees\n",
    "\n",
    "#Import additional packages\n",
    "import os\n",
    "import sys\n",
    "import configparser\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from IPython.core.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Activate logging to access the generated SQL statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "handler = logging.FileHandler('DAT312_HANAML_SQLtrace.log')\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info(\"Start logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Create a SAP HANA connection (context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfctxt = dataframe.ConnectionContext( address=\"<machine>\", port=<SQL-port>,  user=\"<HANA-user>\", password=\"<password>\")\n",
    "dfctxt = dataframe.ConnectionContext( address=\"cloudl000022.wdf.sap.corp\", \n",
    "    port=31053, \n",
    "    user=\"MLLAB_###\", \n",
    "    password=\"Welcome19\",\n",
    "    encrypt='true'\n",
    "    , sslValidateCertificate='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Create SAP HANA dataframe and inspect dataframe attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe using a SQL Statement against the insurance training data set\n",
    "train_df =dfctxt.sql ('select * from MLLAB_SHARE.CUSTOMERCHURN_TRAINSAMPLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, unless you use the collect()-method with the dataframe, no data will be transfered from HANA to Python\n",
    "\n",
    "# review number of records\n",
    "print('Number of records', train_df.count())\n",
    "\n",
    "# review number of columns\n",
    "print('Number of columns', len(train_df.columns))\n",
    "\n",
    "# review columns names and corresponding SQL types \n",
    "print(train_df.dtypes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the target variable 'ContractActivityLABEL' and its value distribution\n",
    "\n",
    "# customer which cancelled the contract in the past\n",
    "print('Customer who churned: ', train_df.filter('\"ContractActivity\" = 1').count()  )\n",
    "# customer which kept their contract\n",
    "print('Customer who could be retained: ',train_df.filter('\"ContractActivity\" = 0').count()  )\n",
    "\n",
    "# calulate ratio: \n",
    "ratio = train_df.filter('\"ContractActivity\" = 1').count() / train_df.filter('\"ContractActivity\" = 0').count()\n",
    "print(ratio)\n",
    "\n",
    "# If you get ~0.25 as a ration of customers who cancelled their contract, \n",
    "# this implies from the training data about 25% of the customers have been cancelling their contract.\n",
    "# Thus the dataset can be described as slightly imbalanced  between the classed 1 (25%) and 0 (75%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's look at the acual data. Collect() will transfer data from the HANA to the python client)\n",
    "train_df.head(5).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show column descriptive statistics using the describe method\n",
    "train_df.describe().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Fit a Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repare feature list \n",
    "featurelist = train_df.columns\n",
    "#print(len(featurelist))\n",
    "featurelist.remove('AccountID')\n",
    "featurelist.remove('ContractActivity')\n",
    "print(len(featurelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert a row into the SQLtrace.log file, to better indentify the start of the actual RDT training call\n",
    "logger.info(\"-----------------training procedure START ----------------------\")\n",
    "\n",
    "# instantiate the object\n",
    "rfc = trees.RandomForestClassifier(conn_context=dfctxt, thread_ratio=1.0, n_estimators=200, max_features=5, \n",
    "                                   random_state=1234,  min_samples_leaf=1\n",
    "                                  , max_depth=20\n",
    "                                   , allow_missing_dependent=False\n",
    "                                   , split_threshold=0.0000001\n",
    "                                  ,  calculate_oob=True\n",
    "                                  , sample_fraction=1\n",
    "                                , strata=[( 0.5, '0',), ( 0.5, '1')]\n",
    "                                , priors=[(0.75, '0'), (0.25, '1')]\n",
    "                                  )    \n",
    "\n",
    "# perform the training\n",
    "rfc.fit(train_df, features= featurelist, label = \"ContractActivity\", key=\"AccountID\")\n",
    "\n",
    "logger.info(\"----------------training procedure END ----------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data confusion matrix\n",
    "rfc.confusion_matrix_.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Model Accuracy on the given validation dataset\n",
    "test_df=dfctxt.sql ('select * from MLLAB_SHARE.CUSTOMERCHURN_TESTSAMPLE')\n",
    "\n",
    "mean_accuracy=rfc.score(test_df, key='AccountID')\n",
    "print(\"Accuracy score is {}\".format(mean_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Predict with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the test dataset\n",
    "test_df = dfctxt.sql ('select * from MLLAB_SHARE.CUSTOMERCHURN_TESTSAMPLE')\n",
    "\n",
    "# testdata set contains 638 records\n",
    "print(test_df.count())\n",
    "\n",
    "# The testdata set contains 136 customers who \"churned\" out of 683.\n",
    "print('Customer who churned: ',test_df.filter('\"ContractActivity\" = 1').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the target column and Predict\n",
    "test_df_trunc = test_df\n",
    "test_df_trunc.drop(['ContractActivity'])\n",
    "\n",
    "logger.info(\"----------------predict START ----------------------\")\n",
    "result_test_pred = rfc.predict(test_df_trunc, key='AccountID', features=featurelist, verbose=False)\n",
    "logger.info(\"----------------predict END ----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction result show predicted classification and its confidence value\n",
    "print(result_test_pred.head(2).collect())\n",
    "\n",
    "# Overall 86 customers where predicted as likely to churn\n",
    "print('Overall number of customers predicted to churn: ',result_test_pred.filter('\"SCORE\" = 1').count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 - Review the SQL trace information\n",
    "\n",
    "- Open the file DAT312_HANAML_SQLtrace.log\n",
    "- review sql code between\n",
    "- -----------------training procedure START ----------------------\n",
    "-     and\n",
    "- ----------------training procedure END ----------------------\n",
    "- inspect the complete SQL code generated by the FIT python method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   \n",
    "### Next exercise \n",
    "- For the next exercise you will work in the SAP WebIDE for SAP HANA\n",
    "- Open webIDE from https://cloudl000022.wdf.sap.corp:53075\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    \n",
    "###    \n",
    "###    \n",
    "### Furher optional steps -- do not continue --  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why are customers interested in buying the new insurance product\n",
    "rfc.feature_importances_.sort(\"IMPORTANCE\", desc=True).head(10).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate additional model quality metrics\n",
    "from hana_ml.algorithms.pal.metrics import accuracy_score \n",
    "\n",
    "result_test_pred2=result_test_pred.rename_columns({'AccountID': 'ID'})\n",
    "test_df2=test_df.rename_columns({'AccountID': 'ID'})\n",
    "\n",
    "# prepare data for calcualting AUC\n",
    "auc_in_pred=result_test_pred2.select('ID', 'SCORE',  \n",
    "                                    ('CASE WHEN SCORE = 1 THEN CONFIDENCE ELSE 1- CONFIDENCE END','PROBABILITY'))\n",
    "\n",
    "auc_in_observed=test_df2.select(('ID', 'ID_O'),('\\\"ContractActivity\\\"', 'ORIGINAL_LABEL'))\n",
    "\n",
    "auc_in=auc_in_observed.join(auc_in_pred, 'ID_O=ID').select('ID', 'ORIGINAL_LABEL', 'PROBABILITY')\n",
    "print(auc_in.head(2).collect())\n",
    "\n",
    "# Calculate AUC\n",
    "auc, roc = algorithms.pal.metrics.auc(dfctxt, auc_in, positive_label='1')\n",
    "print('Test data AUC is: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC data\n",
    "import matplotlib.pyplot as plt\n",
    "roc_print = roc.collect()\n",
    "x = roc_print[\"FPR\"]\n",
    "y = roc_print[\"TPR\"]\n",
    "\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CF-Matrix\n",
    "CF_IN=auc_in_observed.join(auc_in_pred, 'ID_O=ID').select('ID', 'ORIGINAL_LABEL', ('CAST( SCORE as VARCHAR(1))', 'PREDICTED_LABEL' ))\n",
    "print(CF_IN.head(5).collect())\n",
    "#print(CF_IN.dtypes())\n",
    "\n",
    "\n",
    "cm, cr = algorithms.pal.metrics.confusion_matrix(dfctxt, CF_IN, 'ID','ORIGINAL_LABEL','PREDICTED_LABEL', beta=1 )\n",
    "#confusion_matrix(conn_context, data, key, label_true=None, label_pred=None, beta=None, native=True)¶\n",
    "print(cm.collect())\n",
    "print(cr.collect())\n",
    "\n",
    "score = algorithms.pal.metrics.accuracy_score( dfctxt, CF_IN, 'ORIGINAL_LABEL', 'PREDICTED_LABEL')\n",
    "print('Accuracy score is: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
