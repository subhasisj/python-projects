{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netflix Movie Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to recommend movies to users by\n",
    "- By predicting the rating for a movie which has been unrated by the user\n",
    "- Build a model with RMSE (between actual and predicted ratings) as the metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratings prediction need not be calculated instantaneosly as these ratings would be precomputed on a daily basis (May be Nightly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be downloaded from https://www.kaggle.com/netflix-inc/netflix-prize-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each subsequent line in the file corresponds to a rating from a customer and its date in the following format:\n",
    "\n",
    "Columns : __CustomerID, Rating, Date__\n",
    "\n",
    "- MovieIDs range from 1 to 17770 sequentially.\n",
    "- CustomerIDs range from 1 to 2649429, with gaps. There are 480189 users.\n",
    "- Ratings are on a five star (integral) scale from 1 to 5.\n",
    "- Dates have the format YYYY-MM-DD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie information in \"movie_titles.txt\" is in the following format:\n",
    "\n",
    "MovieID,YearOfRelease,Title\n",
    "\n",
    "- MovieID do not correspond to actual Netflix movie ids or IMDB movie ids.\n",
    "- YearOfRelease can range from 1890 to 2005 and may correspond to the release of corresponding DVD, not necessarily its theaterical release.\n",
    "- Title is the Netflix movie title and may not correspond to titles used on other sites. Titles are in English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pose this a ML problem,we can categorize it as :\n",
    "- Recommendation Problem to Recommend Movies\n",
    "- Regression task to predict the ratings for an unrated movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from itertools import islice\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:  - Copy.gitignore --> 0.0MB\n",
      "Filename: .gitignore --> 0.0MB\n",
      "Filename: .ipynb_checkpoints --> 0.0MB\n",
      "Filename: combined_data_1.txt --> 495.03MB\n",
      "Filename: combined_data_2.txt --> 555.21MB\n",
      "Filename: combined_data_3.txt --> 465.16MB\n",
      "Filename: combined_data_4.txt --> 552.54MB\n",
      "Filename: movie_titles.csv --> 0.58MB\n",
      "Filename: probe.txt --> 10.78MB\n",
      "Filename: qualifying.txt --> 52.45MB\n"
     ]
    }
   ],
   "source": [
    "# List all files \n",
    "for file in os.listdir('./data'):\n",
    "    print('Filename: {0} --> {1}'.format(file.ljust(30).rstrip(),\n",
    "                                       str(round(os.path.getsize('./data/'+file)/1000000,2))+'MB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows: ......\n",
      "['1:\\n', '1488844,3,2005-09-06\\n', '822109,5,2005-05-13\\n', '885013,4,2005-10-19\\n', '30878,4,2005-12-26\\n', '823519,3,2004-05-03\\n', '893988,3,2005-11-17\\n', '124105,4,2004-08-05\\n', '1248029,3,2004-04-22\\n', '1842128,4,2004-05-09\\n']\n"
     ]
    }
   ],
   "source": [
    "# Sample Read\n",
    "with open('./data/combined_data_1.txt') as file:\n",
    "    head = list(islice(file,10))\n",
    "print('First 10 rows: ......')\n",
    "print([h for h in head])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['combined_data_1.txt',\n",
       " 'combined_data_2.txt',\n",
       " 'combined_data_3.txt',\n",
       " 'combined_data_4.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all data files\n",
    "files = [f for f in os.listdir('./data/') \\\n",
    "         if re.match('combined_data.*\\.txt',f)]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data has been combined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:49<05:27, 109.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data has been combined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [03:44<03:42, 111.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data has been combined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [05:17<01:45, 105.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data has been combined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [08:43<00:00, 135.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken: 0:08:43.693608\n"
     ]
    }
   ],
   "source": [
    "# Write a file with the final data\n",
    "start_time = datetime.now()\n",
    "if not os.path.isfile('./data/all_data_combined.csv'):\n",
    "    all_data_combined = open('./data/all_data_combined.csv',mode = 'w')\n",
    "# combine all the data into the format movieid','userid','rating','date'\n",
    "    row = list()\n",
    "    for file in tqdm(files):\n",
    "        with open(os.path.join('./data/',file)) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.endswith(':'):\n",
    "               # Then all that follow are ratings untill me revisit the same ':' pattern\n",
    "                    movie_id = line.replace(':','')\n",
    "                else:\n",
    "                    row = [word for word in line.split(',')]\n",
    "                    row.insert(0,movie_id)\n",
    "                    all_data_combined.write(','.join(row))\n",
    "                    all_data_combined.write('\\n')\n",
    "        print('All data has been combined')\n",
    "    all_data_combined.close()\n",
    "print('Total Time Taken: {}'.format(datetime.now() - start_time))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
