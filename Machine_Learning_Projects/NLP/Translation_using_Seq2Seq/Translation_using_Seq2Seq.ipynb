{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will implement a Neural Machine Translation with LSTM using Teacher Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import multiprocessing as mp\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "from dask.diagnostics import ProgressBar\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                             source                               target  \\\n1099                    He gave in.                        Él se rindió.   \n1860                   He was busy.                   Él estaba ocupado.   \n26495         This cat is not ours.             Este gato no es nuestro.   \n15965            Where are my keys?             ¿Dónde están mis llaves?   \n54021  Do you need a place to stay?  ¿Necesitáis un lugar para alojaros?   \n\n                                                comments  \n1099   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n1860   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n26495  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n15965  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n54021  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>target</th>\n      <th>comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1099</th>\n      <td>He gave in.</td>\n      <td>Él se rindió.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n    </tr>\n    <tr>\n      <th>1860</th>\n      <td>He was busy.</td>\n      <td>Él estaba ocupado.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n    </tr>\n    <tr>\n      <th>26495</th>\n      <td>This cat is not ours.</td>\n      <td>Este gato no es nuestro.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n    </tr>\n    <tr>\n      <th>15965</th>\n      <td>Where are my keys?</td>\n      <td>¿Dónde están mis llaves?</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n    </tr>\n    <tr>\n      <th>54021</th>\n      <td>Do you need a place to stay?</td>\n      <td>¿Necesitáis un lugar para alojaros?</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data = pd.read_table('./Data/spa.txt',names=['source','target','comments'])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<Client: 'tcp://127.0.0.1:49448' processes=4 threads=8, memory=16.00 GB>",
      "text/html": "<table style=\"border: 2px solid white;\">\n<tr>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Client</h3>\n<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n  <li><b>Scheduler: </b>tcp://127.0.0.1:49448</li>\n  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n</ul>\n</td>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Cluster</h3>\n<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n  <li><b>Workers: </b>4</li>\n  <li><b>Cores: </b>8</li>\n  <li><b>Memory: </b>16.00 GB</li>\n</ul>\n</td>\n</tr>\n</table>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "num_partitions = 10 #number of partitions to split dataframe\n",
    "num_cores = mp.cpu_count() #number of cores on your machine\n",
    "Client(n_workers=4, threads_per_worker=2, memory_limit='4GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove HTML Tags\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text,'lxml')\n",
    "    html_free_text = soup.get_text()\n",
    "    return html_free_text\n",
    "\n",
    "# Remove Punctuations\n",
    "special_characters= set(string.punctuation)\n",
    "def punctuation_remover(text):\n",
    "    punctuation_free_text = \" \".join([word for word in text if word \\\n",
    "                                    not in special_characters])\n",
    "    return punctuation_free_text\n",
    "\n",
    "\n",
    "# Convert to lower case\n",
    "def convert_to_lowercase(tokens):\n",
    "    low = []\n",
    "    for tok in tokens:\n",
    "        low.append(tok.lower().strip())\n",
    "    return low\n",
    "\n",
    "# Lemmatization\n",
    "def lemmatize_words(text):\n",
    "    words = nlp(str(text))\n",
    "    return [word.lemma_ for word in words if word.lemma_ != '-PRON-']  \n",
    "\n",
    "\n",
    "num_digits= str.maketrans('','', digits)\n",
    "remove_digits = lambda x: x.translate(num_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_for_tasks(text, for_pos_tagging = False):\n",
    "    cleaned_text = remove_html(text)\n",
    "    cleaned_text = word_tokenize(cleaned_text)\n",
    "    cleaned_text = lemmatize_words(cleaned_text)\n",
    "    cleaned_text = punctuation_remover(cleaned_text)\n",
    "    cleaned_text = remove_digits(cleaned_text)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_df = dd.from_pandas(data,npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Dask DataFrame Structure:\n               source  target comments\nnpartitions=8                         \n0              object  object   object\n15472             ...     ...      ...\n...               ...     ...      ...\n108304            ...     ...      ...\n123769            ...     ...      ...\nDask Name: from_pandas, 8 tasks",
      "text/html": "<div><strong>Dask DataFrame Structure:</strong></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>target</th>\n      <th>comments</th>\n    </tr>\n    <tr>\n      <th>npartitions=8</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>object</td>\n      <td>object</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>15472</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108304</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>123769</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div>Dask Name: from_pandas, 8 tasks</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "source      0.0\ntarget      0.0\ncomments    0.0\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "missing_values = dask_df.isnull().sum()\n",
    "with ProgressBar():\n",
    "    missing_percent = ((missing_values / dask_df.index.size)*100).compute()\n",
    "missing_percent  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df['cleaned_source'] = df.source.map(clean_text_for_tasks)\n",
    "    df['cleaned_target'] = df.target.map(clean_text_for_tasks)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_source'] = -1\n",
    "data['cleaned_target'] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "result = dask_df.map_partitions(clean_df,meta=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Time Taken for Processing 123770 rows with Dask(4 Workers ,8 Cores) : 962.1482224464417 \n"
    }
   ],
   "source": [
    "df = result.compute()\n",
    "print(f'Time Taken for Processing {df.shape[0]} rows with Dask(4 Workers ,8 Cores) : {time.time()-start} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  source   target                                           comments  \\\n0    Go.      Ve.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...   \n1    Go.    Vete.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...   \n2    Go.    Vaya.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...   \n3    Go.  Váyase.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...   \n4    Hi.    Hola.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...   \n\n  cleaned_source cleaned_target  \n0             go             Ve  \n1             go           Vete  \n2             go           Vaya  \n3             go         Váyase  \n4             hi           Hola  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>target</th>\n      <th>comments</th>\n      <th>cleaned_source</th>\n      <th>cleaned_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Ve.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n      <td>go</td>\n      <td>Ve</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Go.</td>\n      <td>Vete.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n      <td>go</td>\n      <td>Vete</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Go.</td>\n      <td>Vaya.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n      <td>go</td>\n      <td>Vaya</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Go.</td>\n      <td>Váyase.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n      <td>go</td>\n      <td>Váyase</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hi.</td>\n      <td>Hola.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n      <td>hi</td>\n      <td>Hola</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if GPU's are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Num GPUs Available:  1\n"
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagginng Sentences with BOS and EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cleaned_target = df.cleaned_target.apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000 # max no. of words for tokenizer , Top 5000 Words in the Vocabulary\n",
    "MAX_SEQUENCE_LENGTH = 200 # max length of each entry (sentence)\n",
    "EMBEDDING_DIM = 300      # embedding dimensions for word vectors\n",
    "OOV_TOKEN = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_creator(texts,VOCAB_SIZE=VOCAB_SIZE):\n",
    "     tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE)\n",
    "     tokenizer.fit_on_texts(texts)\n",
    "     word_index_dictionary = tokenizer.word_index\n",
    "\n",
    "     word2index = {}\n",
    "     index2word = {}\n",
    "     for key,value in word_index_dictionary.items():\n",
    "         if value < VOCAB_SIZE:\n",
    "             word2index[key] = value\n",
    "             index2word[value] = key\n",
    "         if value >= VOCAB_SIZE-1:\n",
    "             continue\n",
    "     return word2index ,index2word\n",
    "\n",
    "\n",
    "\n",
    "# return word_index\n",
    "# dict(list(word_index.items())[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_word2index ,source_index2word = vocab_creator(df.cleaned_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{1: 'be',\n 2: 'the',\n 3: 'to',\n 4: 'tom',\n 5: 'do',\n 6: 'a',\n 7: \"n't\",\n 8: 'have',\n 9: \"'s\",\n 10: 'that',\n 11: 'in',\n 12: 'of',\n 13: 'this',\n 14: 'go',\n 15: 'for'}"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "dict(list(source_index2word.items())[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word2index ,target_index2word = vocab_creator(df.cleaned_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'start': 1,\n 'end': 2,\n 'de': 3,\n 'que': 4,\n 'no': 5,\n 'a': 6,\n 'tom': 7,\n 'la': 8,\n '¿': 9,\n 'el': 10,\n 'en': 11,\n 'es': 12,\n 'un': 13,\n 'se': 14,\n 'por': 15}"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "dict(list(target_word2index.items())[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}