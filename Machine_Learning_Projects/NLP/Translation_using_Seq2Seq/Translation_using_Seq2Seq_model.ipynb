{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now implement the LSTM Model for training the NMT with the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000 # max no. of words for tokenizer , Top 5000 Words in the Vocabulary\n",
    "MAX_SEQUENCE_LENGTH = 200 # max length of each entry (sentence)\n",
    "EMBEDDING_DIM = 300      # embedding dimensions for word vectors\n",
    "OOV_TOKEN = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  source   target                                           comments  \\\n0    Go.      Ve.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...   \n1    Go.    Vete.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...   \n2    Go.    Vaya.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...   \n3    Go.  V치yase.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...   \n4    Hi.    Hola.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...   \n\n  cleaned_source      cleaned_target  \n0             go      START_ Ve _END  \n1             go    START_ Vete _END  \n2             go    START_ Vaya _END  \n3             go  START_ V치yase _END  \n4             hi    START_ Hola _END  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>target</th>\n      <th>comments</th>\n      <th>cleaned_source</th>\n      <th>cleaned_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Ve.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n      <td>go</td>\n      <td>START_ Ve _END</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Go.</td>\n      <td>Vete.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n      <td>go</td>\n      <td>START_ Vete _END</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Go.</td>\n      <td>Vaya.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n      <td>go</td>\n      <td>START_ Vaya _END</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Go.</td>\n      <td>V치yase.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n      <td>go</td>\n      <td>START_ V치yase _END</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hi.</td>\n      <td>Hola.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n      <td>hi</td>\n      <td>START_ Hola _END</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Read Data\n",
    "df = pd.read_csv('./Data/cleaned_data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word2index and index2word\n",
    "def vocab_creator(texts,vocab_size = VOCAB_SIZE):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    word_index_dictionary = tokenizer.word_index\n",
    "\n",
    "    word2index = []\n",
    "    index2word = []\n",
    "\n",
    "    for key,value in word_index_dictionary.items():\n",
    "        if value < VOCAB_SIZE:\n",
    "            word2index[key] = value\n",
    "            index2word[value] = key\n",
    "        if value >= VOCAB_SIZE-1:\n",
    "             continue\n",
    "    return word2index,index2word\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bittfgpuconda8c93ae4dbbaa45ec99f8c451c42cb5ee",
   "display_name": "Python 3.6.10 64-bit ('tfgpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}